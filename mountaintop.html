---
layout: page
title: Mountaintop Summer Experience
---

<html>
<head>
  <title>Mountaintop Summer Experience</title>
</head>
<body>
  <h1>General Information</h1>
  <p>Air pollution has been identified as one of the biggest threats to human health by the WHO Global Air Quality Guidelines, leading to respiratory disease, cardiovascular disease, and cancer. This project will implement innovative AI (Artificial Intelligence) techniques to provide fine-grained air quality sensing for residents in areas without air quality monitoring sensors.</p>
  
  <img src="{{ site.baseurl }}/public/air-pollution.png" alt="Mountaintop Summer Experience">
  
  <h2>Blog</h2>
  
  
<div class="log">
  <h3>Week One</h3>
  <p>I am very excited to start working on the Breath of The City Project. This is my first time working on a high impact project, and I am motivated to put in the work. Me and my team work well together, and I am happy to have them working alongside me.</p>
  <p>We have assigned roles and initiated research on the project. I will be focusing on the AI model. The AI model will need to predict air quality for any given location. The first step is determining which data affects air quality the most and will be utilized by the model.</p>
  <p>We need the model to incorporate spatial and temporal environment data. The spatial data includes details such as POIs (factories, buildings, plants), and road networks. The temporal details are sequential and change over time. The most prevalent temporal features are nearby air quality sensor records and nearby meteorological data (temperature, humidity, pressure, wind speed/direction, and weather).</p>
  <p>The type of model we are planning to implement right now is an LSTM-FCNs. Implementing an LSTM-FCN involves combining the Long Short-Term Memory (LSTM) and Fully Convolutional Network (FCN) architectures. This type of neural network combines the strengths of LSTM and CNN architectures. It can capture both temporal dependencies and spatial patterns, making it suitable for estimating air pollution based on both spatial and temporal data.</p>
  <p>We plan to extract both the static and sequential environment features from public APIs to feed the model. I have spent a lot of time this week going through different API documentation to see if they fit our needs. This involves checking the different payment plans, ensuring accurate data, and consistent functionality, among other considerations.</p>
  <p>This week was primarily a research week, and we plan on sharing our findings with Professor Yang during our upcoming meeting with him next Monday. We have been finding and reading research papers that have similar goals as our project through Google Scholar.</p>
    <img src="{{ site.baseurl }}/public/todo.jpg" alt="ToDo List">
    <img src="{{ site.baseurl }}/public/example-reinforcement-learning-system.jpg" alt="example-reinforcement-learning-system">
    <img src="{{ site.baseurl }}/public/exampleAPI.png" alt="exampleAPI">
  </div>
  
  
<div class="log">
  <h3>Week Two</h3>
  <p>After completing our initial research phase, we delved into the world of APIs to collect the necessary data for our Breath of The City Project. This week was all about exploring different APIs and considering various factors to ensure we gather accurate and reliable information for our AI model.</p>
  <p>One of the key aspects we had to consider when evaluating APIs was their data specifications. We needed APIs that provided detailed spatial and temporal environmental data, including information about points of interest (POIs) such as factories and buildings, as well as road networks. Additionally, we required access to sequential data like air quality sensor records and meteorological data (temperature, humidity, pressure, wind speed/direction, and weather) to capture temporal patterns effectively.</p>
  <p>Reliability was another crucial factor we assessed. We wanted APIs that consistently provided up-to-date and reliable data. Ensuring the APIs had a good track record of delivering accurate information was essential for the success of our AI model.</p>
  <p>Price was also a consideration since some APIs offer tiered pricing plans based on usage or premium features. We had to find a balance between the quality of the data provided and our project budget.</p>
  <p>During our exploration, we tested several APIs to determine their suitability for our project. Some of the APIs we experimented with were AirNow, NCEI (National Centers for Environmental Information), weather.gov, OSMnx, OpenAQ, and OpenWeather. Each API had its own strengths and weaknesses, and we carefully evaluated their data quality, reliability, and pricing structures to make informed decisions.</p>
  <p>As we progressed through this API exploration phase, we documented our findings and compared the pros and cons of each API. This documentation will be valuable when we present our recommendations to Professor Yang during our upcoming meeting. We aim to select the APIs that best align with our project's requirements and constraints.</p>
</div>
<div class="log">
  <h3>Week Three</h3>
  <p>Week three of the Breath of The City Project was eventful, with a mix of work and reflection. On Monday, we observed Juneteenth and took the day off to commemorate the historic occasion.</p>
  <p>During the rest of the week, I focused on automating the processing of CSV files containing essential data for different cities. To streamline the data collection process, I developed a program that takes an Excel spreadsheet as input, containing a list of cities and their coordinates. The program then retrieves road map data for each city listed in the spreadsheet. This automation significantly reduces manual effort and ensures consistent data collection across cities.</p>
  <p>Additionally, we dedicated time to reviewing the outputted data from the APIs we selected in the previous weeks. This step was crucial to verify the accuracy and relevance of the data. We examined the data points obtained from the APIs and cross-referenced them with other reliable sources to validate their consistency.</p>
  <p>Furthermore, we had the opportunity to dive into a research paper on graph convolutional networks (GCNs) focused on traffic monitoring. The paper explored how GCNs can be utilized to analyze and model traffic patterns, providing valuable insights for our own project. Understanding the latest advancements and techniques in the field enables us to enhance our AI model's capabilities and adapt it to different urban contexts.</p>
  <p>Overall, week three was a productive week that involved automation, data verification, and knowledge enrichment. These activities contribute to the development of a robust and reliable air quality prediction model that can make a positive impact on our environment.</p>
</div>
<div class="log">
  <h3>Week Four</h3>
  <p>During week four of our Breath of The City Project, our team made significant progress in our research and implementation efforts.</p>
  <p>We started by completing a thorough literature review of DCRNN papers related to traffic and air prediction. This review helped us gain a deeper understanding of the concepts and techniques employed in DCRNN models.</p>
  <p>To further enhance our knowledge, we explored existing GitHub implementations of DCRNN. By examining these implementations, we gained practical insights into the implementation details and potential challenges associated with DCRNN models.</p>
  <p>We also dedicated time to learning about Graph Neural Networks (GNNs), which are fundamental to DCRNNs. This preliminary understanding of GNNs allowed us to grasp the underlying principles and mechanisms behind DCRNN models.</p>
  <p>One of the tasks assigned to me during week four was road map data collection for 15 populated cities. This involved gathering relevant data to construct road networks for these cities, which is crucial for the accurate modeling and prediction of traffic and air quality. The collected data will serve as a foundation for our subsequent modeling and analysis.</p>
  <p>In addition to road map data collection, we successfully completed the code to find the coordinates of all bodies of water in individual cities as well as their areas. This information is valuable for our project as bodies of water can significantly impact air quality and environmental patterns within urban areas.</p>
</div>
<div class="log">
  <h3>Week Five</h3>
  <p>This week, my focus was on researching Voronoi graphs and exploring their potential applications in graphing spatial data for our AI model.</p>
  <p>Voronoi graphs are a powerful tool for representing spatial relationships and analyzing proximity in geographical datasets. They can divide a given space into regions based on the proximity to a set of points, providing insights into the spatial distribution of data points.</p>
  <p>In our project, Voronoi graphs can be utilized to represent the spatial distribution of environmental factors such as air quality, temperature, humidity, and more. By constructing a Voronoi graph using sensor locations as input points, we can create a network of regions that captures the influence of each sensor on the surrounding area.</p>
  <p>This week, I also implemented simple programs utilizing Voronoi graph building packages. These programs allowed me to generate Voronoi graphs based on sensor locations and visualize the resulting spatial divisions. Through experimentation, I explored different metrics and edge weighting schemes to understand their impact on the graph structure.</p>
  <p>By leveraging Voronoi graphs, we aim to enhance the spatial analysis capabilities of our AI model and improve the accuracy of our predictions. In the coming weeks, we will further refine our Voronoi-based approach and integrate it into our overall prediction pipeline.</p>
</div>
<div class="log">
  <h2>Week Six: Historical Purple Air Data Collection and Expo Preparation</h2>
  <p>This week was action-packed as we made significant strides in our Breath of The City Project. My main focus was on collecting historical Purple Air data from Dallas, a critical step to feed into our graph convolutional network.</p>
  <p>The dataset I collected spans the entirety of Dallas and contains half a year's worth of data in 30-minute intervals. This vast and granular dataset will provide valuable insights into air quality patterns and fluctuations in the city. It's essential for training our AI model accurately.</p>
  <p>Additionally, I collaborated with my fellow teammate, Jhansi, to prepare for our big expo presentation. We worked on crafting and practicing our 3-minute pitch, ensuring that we present the project's goals, methodology, and potential impact effectively. The expo presentation will be a crucial opportunity to showcase our work and gather valuable feedback.</p>
  <p>As we move forward, we're eager to incorporate the historical Purple Air data into our graph convolutional network and see how it enhances the model's predictive capabilities. The combination of spatial and temporal environmental data with advanced deep learning techniques holds tremendous promise for accurate air quality prediction in urban areas.</p>
  <img src="{{ site.baseurl }}/public/feature_extraction.jpg" alt="Feature Extraction">
</div>
<div class="log">
  <h2>Week Seven: Grid Script Development and Poster Preparation</h2>
  <p>Week seven brought new challenges and exciting developments to the project. One of the key tasks I tackled this week was developing scripts for gridding bodies of water, land regions, and road networks.</p>
  <p>The grid script allows us to take the data related to bodies of water, land regions, or road networks, along with a specific small grid, and efficiently calculate the area of that region within the grid. This capability is crucial for our graph convolutional networks (GCNs) as it enables us to map environmental features within the city more accurately and at a finer granularity.</p>
  <p>By incorporating grid-based calculations, our GCN can better understand the spatial distribution of environmental factors and their interactions, leading to more precise predictions of air quality and urban dynamics.</p>
  <p>Furthermore, my teammates and I dedicated time to designing a poster for an upcoming event. During this event, we will present our project and interact with visitors, explaining the project's goals, methodologies, and potential impacts.</p>
  
  <img src="{{ site.baseurl }}/public/weeklytasks.jpg" alt="Weekly Tasks">
  <img src="{{ site.baseurl }}/public/weeklytasks2.jpg" alt="Weekly Tasks 2">

</div>
  
  <!-- Repeat the above "log" div for each blog entry -->
  
</body>
</html>